{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path to all files in all folders in /dataset/raw\n",
    "# On first version, do only /dataset/raw/AtasCDINF\n",
    "# return list with paths to files\n",
    "import os\n",
    "dataset_basedir = \"D:\\\\Documentos\\\\PFC-projeto\\\\dataset\"\n",
    "rawPDF_dir = dataset_basedir + \"\\\\raw\\\\AtasCDINF\\\\atasPDF\\\\\"\n",
    "def listDirectory(raw_dir):\n",
    "    files = os.listdir(raw_dir)\n",
    "    files = [raw_dir + file_path for file_path in files]\n",
    "    return files\n",
    "\n",
    "files_pdf = listDirectory(rawPDF_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "def extractDocxData(path):\n",
    "    \"\"\"Extract text from word documents\"\"\"\n",
    "    # doc = docx2txt.process(path)\n",
    "    # return doc\n",
    "\n",
    "    doc = docx.Document(path)\n",
    "    output = \"\"\n",
    "    for paragraph in doc.paragraphs:\n",
    "        output = output + \"\\n\" + paragraph.text\n",
    "    return output\n",
    "\n",
    "import fitz\n",
    "import pytesseract\n",
    "def extractPDFData(path):\n",
    "    \"\"\"Extract all data from a pdf (from both image and text)\"\"\"\n",
    "    # Open file\n",
    "    file = fitz.open(path)\n",
    "    pages = file.pages()\n",
    "    output = \"\"\n",
    "    # cycle thru all pages\n",
    "    for pageNumber, page in enumerate(pages):\n",
    "        images = page.getImageList()\n",
    "        # extract text from the images on the page\n",
    "        for imgNumber, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            pix = fitz.Pixmap(file,xref)\n",
    "            if pix.n > 4:\n",
    "                pix = fitx.Pixmap(fitz.csRGB, pix)\n",
    "            pillowPix = convertToPillow1(pix)\n",
    "            string = pytesseract.image_to_string(\n",
    "                pillowPix,\n",
    "                lang='por',\n",
    "                config='--tessdata-dir .'\n",
    "            )\n",
    "            # annex the extracted data to the output\n",
    "            output = output + ' ' + string\n",
    "        # extract plain text from the file\n",
    "        text = page.getText()\n",
    "        # annext the extracted text to the output\n",
    "        output = output + ' ' + text\n",
    "    return output\n",
    "\n",
    "# Extract data\n",
    "import re\n",
    "def extractData(path):\n",
    "    \"\"\" Checks if the document is a PDF or a docx. If it's neither, return an error\"\"\"\n",
    "    # declare as internal function (takes extension as argument, and returns true or false if it is)\n",
    "    def assertExtension(fileName, extension):\n",
    "        # create list of matches with match (regex pattern is \\.{extension}$)\n",
    "        matches = re.findall(f\"\\.{extension}$\", fileName)\n",
    "        # if the list has len == 0, return false\n",
    "        if len(matches) == 0:\n",
    "            return False\n",
    "        # otherwise, return True\n",
    "        else:\n",
    "            return True\n",
    "    # Verify extension\n",
    "    # return string with extracted data\n",
    "    if assertExtension(path, \"pdf\"):\n",
    "        # if it's pdf, apply extractPDFData function\n",
    "        return extractPDFData(path)\n",
    "    elif assertExtension(path, \"docx\"):\n",
    "        # if it's docx, apply extractDocxData function\n",
    "        return extractDocxData(path)\n",
    "    else:\n",
    "        # if it's something else, raise ValueError exception\n",
    "        raise ValueError(f\"Invalid file format provided: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "def dataCleaning(fileString):\n",
    "    \"\"\"Use regular expressions to find the paragraph enumerations, and clean them up. Then also clean up the signature blanks\"\"\"\n",
    "    import re\n",
    "    # Use regex to detect \\ndd \\n patterns and delete them\n",
    "    output = re.sub(\"\\n\\d* \", \"\", fileString)\n",
    "    # Use regex to detect \\ndd\\n patterns and delete them\n",
    "    output = re.sub(\"\\n\\d+\", \"\", output)\n",
    "    # Use regex to detect signatures, and delete them\n",
    "    output = re.sub(\"_*\", \"\", output)\n",
    "    # New lines don't have any meaning here. Delete them\n",
    "    output = output.replace(\"\\n\", \" \")\n",
    "    # Return cleaned fileString\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On first version, do only /dataset/final/AtasCDINF\n",
    "def saveToFile(file_path, file_string):\n",
    "    with open(f\"{file_path}.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "        text_file.write(file_string)\n",
    "# ex: saveToFile(\"ATA5\", ata5_cleaned)\n",
    "# Save resulting file into /dataset/final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open all paths one by one and extract data from PDF or word\n",
    "def preprocessFiles(pathList, originalExtension):\n",
    "    # loop thru list of paths\n",
    "    for path in pathList:\n",
    "        # pass path to extractData function, take return value\n",
    "        data = extractData(path)\n",
    "        # clean extracted data\n",
    "        data = dataCleaning(data)\n",
    "        # save as file on final path\n",
    "        # just replace the word raw with the word final in the path\n",
    "        # also delete the file extension\n",
    "        finalPath = path.replace(\"raw\", \"final\").replace(originalExtension, \"\")\n",
    "        saveToFile(finalPath, data)\n",
    "\n",
    "preprocessFiles(files_pdf, \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for the docx files, just for sure\n",
    "rawDOCX_dir = dataset_basedir + \"\\\\raw\\\\AtasCDINF\\\\atasDOCX\\\\\"\n",
    "files_docx = listDirectory(rawDOCX_dir)\n",
    "preprocessFiles(files_docx, \".docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
